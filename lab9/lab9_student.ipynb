{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in Medicine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BMSC-GA 4493, BMIN-GA 3007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 9: Autoencoders\n",
    "credits: Juiting Hsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "- denoising auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import copy\n",
    "\n",
    "torch.manual_seed(1111);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available:\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Data Loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(digits):\n",
    "    grids = make_grid(digits, nrow=8)\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.imshow(grids.numpy()[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(train_loader))\n",
    "plot_digits(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(data + torch.FloatTensor(data.size()).normal_(mean=0, std=0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Denoising Auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As covered in class, there are mainly two components to an autoencoder: an encoder and a decoder. For this tutorial, we will be using a very simple model with just one hidden layer (not including the output layer), as shown by the image below. The decoder will just be the mirror of the encoder. Rather than learning an undercomplete representation, we will attempt to learn an overcomplete representation by training a [**sparse autoencoder**](https://web.stanford.edu/class/cs294a/sparseAutoencoder_2011new.pdf). In other words, the \"code\" that our autoencoder learn will be of the same dimension as the input data (28 * 28 = 784). We will, however, add a dropout layer to enforce the sparsity.\n",
    "\n",
    "Another thing to note is that rather than treating out input as 2-dimensional (28 x 28), we will transform our input to 1-dimensional vectors (784) for simplicity.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*ZEvDcg1LP7xvrTSHt0B5-Q@2x.png\" alt=\"alt text\" width=\"300\" height=\"120\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the code skeleton below to implement your own autoencoder. Think about the dimensions to the components of the modules (encoder and decoder). If you're looking for a more complex architecture, it would probably be better to write separate classes of Encoder and Decoder, then include them both in the model. However, since we're using pretty straightforward MLPs, we can do that in a single class by utilizing the ```nn.Sequential``` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, code_dim, dropout_rate=0.15):\n",
    "        \"\"\"\n",
    "        :param input_dim: dimension of input to autoencoder\n",
    "        :param hidden_dim: dimension of hidden layer in encoder and decoder\n",
    "        :param code_dim: dimension of code in autoencoder\n",
    "        \"\"\"\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # TODO: initialize your Encoder and Decoder class with the given parameters\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward function for the autoencoder. Remember to add dropout to enforce sparsity!\n",
    "        Return both the output from the decoder and the code from the encoder\n",
    "        :return output, code\n",
    "        \"\"\"\n",
    "        # TODO: autoencoder forward function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will train our autoencoder to denoise handwritten digit image data. Use the functions below and complete the code where necessary. Think about what kind of loss to use as the reconstruction loss for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(loader, model, limit=None):\n",
    "    \"\"\"\n",
    "    Help function that tests the models's performance on a dataset\n",
    "    :param: loader: data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    truths = []\n",
    "    \n",
    "    for i, (data, labels) in enumerate(loader):\n",
    "        if i and i==limit:\n",
    "            break\n",
    "        data_noise = data + torch.FloatTensor(data.size()).normal_(std=NOISE_STD)\n",
    "        outputs, _ = model(data_noise.squeeze().view(-1, 28 * 28).to(device))\n",
    "        # compute loss\n",
    "        loss += loss_function(outputs, data.view(-1,28*28).to(device)).item() * data.size()[0]\n",
    "        num_samples += data.size()[0]\n",
    "\n",
    "    return loss/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epoch, model):\n",
    "    for epoch in range(num_epoch):\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            # TO DO: add gaussian noise to data\n",
    "            \n",
    "            outputs, _ = model(data_noise.squeeze().view(-1, 28 * 28).to(device))\n",
    "            model.zero_grad()\n",
    "            loss = loss_function(outputs, data.view(-1,28*28).to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "             # report performance\n",
    "            if (i + 1) % LOG_INTERVAL == 0:\n",
    "                test_loss = test_model(test_loader, model)\n",
    "                print('Epoch: [{0}/{1}], Step: [{2}/{3}], Train Loss: {4}, Validation Loss:{5}'.format(\n",
    "                    epoch + 1, EPOCHS, i + 1, len(train_loader), loss.item(), test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 6\n",
    "LOG_INTERVAL = 300\n",
    "\n",
    "LR = 0.002\n",
    "NOISE_STD = 0.6\n",
    "\n",
    "model = AutoEncoder(28 * 28, 200, 784).to(device)\n",
    "\n",
    "# TODO: loss function for reconstruction loss\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "train(EPOCHS, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how we can use our trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(test_loader))\n",
    "plot_digits(data)\n",
    "plt.title(\"Sampled original data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_noise = data + torch.FloatTensor(data.size()).normal_(mean=0, std=NOISE_STD)\n",
    "plot_digits(data_noise)\n",
    "plt.title(\"Data with Gaussian noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise the data\n",
    "model.eval()\n",
    "reconstruction, _ = model(data_noise.view(-1, 28 * 28).to(device))\n",
    "\n",
    "reconstruction = reconstruction.view(-1, 1, 28, 28).data.cpu()\n",
    "plot_digits(reconstruction)\n",
    "plt.title(\"Reconstructed (denoised) images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of High dimensional vectors using t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful Link to understand t-SNE and how to interpret the visualization: https://distill.pub/2016/misread-tsne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(perplexity=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = []\n",
    "y_np = []\n",
    "encoded_data_np = []\n",
    "for data in train_loader:\n",
    "    encoded_data = model.encoder(data[0].view(-1,28*28).to(device)).cpu().detach().numpy()\n",
    "    encoded_data_np.append(encoded_data)\n",
    "    data_np.append(data[0].view(-1,28*28).numpy())\n",
    "    y_np.append(data[1].numpy())\n",
    "data_np = np.concatenate(data_np, axis = 0)[:2500,:]\n",
    "y_np = np.concatenate(y_np)[:2500]\n",
    "encoded_data_np = np.concatenate(encoded_data_np,axis = 0)[:2500,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_data = tsne.fit_transform(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_encoded = tsne.fit_transform(encoded_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "for i in range(10):\n",
    "    plt.scatter(red_data[:,0][y_np == i],red_data[:,1][y_np == i], label = str(i), alpha = 0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "for i in range(10):\n",
    "    plt.scatter(red_encoded[:,0][y_np == i],red_encoded[:,1][y_np == i], label = str(i), alpha = 0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
